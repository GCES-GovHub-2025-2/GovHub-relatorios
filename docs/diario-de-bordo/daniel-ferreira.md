# Di√°rio de Bordo ‚Äì Daniel Ferreira

**Disciplina:** Gest√£o de Configura√ß√£o e Evolu√ß√£o de Software (GCES)  
**Equipe:** GovHub  
**Comunidade/Projeto de Software Livre:** GovHub-br  

---

## Sprint 0 ‚Äì 01/09/2025 ‚Äì 10/09/2025  

### Resumo da Sprint  

Nesta sprint inicial, foquei principalmente em estudar o projeto GovHub-br, entendendo sua proposta e principais tecnologias utilizadas, al√©m de realizar a configura√ß√£o completa do ambiente de desenvolvimento.  

### Atividades Realizadas  

| Data | Atividade | Tipo | Link/Refer√™ncia | Status |  
|------|-----------|------|-----------------|---------|  
| 02/09 | An√°lise inicial do reposit√≥rio GovHub-br | Estudo | https://github.com/GovHub-br/data-application-gov-hub | ‚úÖ Conclu√≠do |  
| 03/09 | Estudo da documenta√ß√£o do projeto GovHub-br | Estudo | README.md e docs oficiais | ‚úÖ Conclu√≠do |  
| 06/09 | Setup completo do ambiente Docker | Implementa√ß√£o | docker-compose.yml | ‚úÖ Conclu√≠do |  

### Maiores Avan√ßos  

* Consegui configurar e rodar o ambiente local.  
* Compreens√£o inicial sobre a proposta do GovHub-br e seu impacto.  

### Maiores Dificuldades  

* A quantidade de tecnologias diferentes envolvidas (Airflow, dbt, Superset) exige tempo para entender como tudo se conecta.  
* Foi necess√°rio revisar a documenta√ß√£o algumas vezes at√© conseguir configurar o ambiente corretamente.  

### Aprendizados  

* Entendi melhor os conceitos de containeriza√ß√£o e como o Docker simplifica a replica√ß√£o de ambientes de dados.  
* Aprendi sobre a import√¢ncia de organizar os dados em camadas (Bronze, Silver e Gold).
* Percebi como uma documenta√ß√£o clara e detalhada sobre a configura√ß√£o do ambiente √© crucial para agilizar o processo de onboarding de novos contribuidores.

### Plano Pessoal para a Pr√≥xima Sprint  

* [ ] Aprofundar o estudo nos modelos dbt.  
* [ ] Explorar os pipelines no Airflow para entender a orquestra√ß√£o.
* [ ] Estudar mais sobre as ferramentas Jupyter, Superset e Airflow para an√°lise e visualiza√ß√£o. 
* [ ] Contribuir com melhorias de documenta√ß√£o ou resolver alguma issue.  

### Reflex√µes Pessoais  

Foi uma sprint de introdu√ß√£o, mas j√° deu para perceber o potencial de aprendizado t√©cnico e impacto social do projeto. Senti que dominar essas ferramentas vai ser importante n√£o s√≥ para o projeto, mas tamb√©m para minha forma√ß√£o como engenheiro de software.  

---

## Sprint 1 ‚Äì 11/09/2025 ‚Äì 24/09/2025

### Resumo da Sprint

Ap√≥s a fase de imers√£o e configura√ß√£o do ambiente na Sprint 0, esta sprint marcou meu primeiro mergulho profundo no desenvolvimento de uma pipeline de dados para o GovHub-br. Fui designado para a issue de cria√ß√£o de uma DAG de ingest√£o para os detalhes e recursos de deputados.

O desafio consistiu em desenvolver um workflow no Apache Airflow capaz de ler os IDs dos deputados j√° existentes na base, consultar dinamicamente m√∫ltiplos endpoints da API de Dados Abertos da C√¢mara para cada um deles e persistir essas informa√ß√µes em tabelas `raw` dedicadas. O foco foi garantir que o processo fosse idempotente ‚Äî permitindo reprocessamentos sem duplicar dados ‚Äî e escal√°vel, estabelecendo uma base s√≥lida para a constru√ß√£o de perfis detalhados sobre os representantes p√∫blicos

### Atividades Realizadas

| Data | Atividade | Tipo | Link/Refer√™ncia | Status |
|---|---|---|---|---|
| 12/09 | Estudo de padr√µes de DAGs din√¢micas no Airflow para itera√ß√£o sobre m√∫ltiplos IDs | Estudo | Documenta√ß√£o Airflow & artigos t√©cnicos | ‚úÖ Conclu√≠do |
| 15/09 | An√°lise e mapeamento dos endpoints da API de Dados Abertos da C√¢mara referentes a `/deputados/{id}` | Estudo | [API Dados Abertos - Deputados](https://dadosabertos.camara.leg.br/api/v2/deputados) | ‚úÖ Conclu√≠do |
| 18/09 | Reuni√£o de alinhamento da equipe para distribui√ß√£o das responsabilidades e defini√ß√£o de padr√µes de desenvolvimento | Discuss√£o | - | ‚úÖ Conclu√≠do |
| 20/09 | Defini√ß√£o da estrat√©gia de persist√™ncia com `UPSERT` para garantir idempot√™ncia na ingest√£o de dados | C√≥digo/Design | Documenta√ß√£o do PostgreSQL | ‚úÖ Conclu√≠do |
| 23/09 | Desenvolvimento da DAG para orquestrar a ingest√£o de detalhes dos deputados por ID | C√≥digo | [Link do PR](https://github.com/GCES-GovHub-2025-2/data-application-gov-hub/issues/5)/ | üöß Em andamento |

### Maiores Avan√ßos

* **Base de uma DAG escal√°vel:** Consegui criar uma estrutura de DAG que busca dados por ID, um padr√£o que poderemos reusar em outras ingest√µes.
* **Integridade dos dados garantida:** Implementei a l√≥gica de `UPSERT` (INSERT/UPDATE), o que deixa a pipeline mais segura contra falhas e reprocessamentos.
* **Primeiro contato com a API da C√¢mara:** Tive minha primeira experi√™ncia pr√°tica com a API de Dados Abertos, entendendo melhor como ela funciona.
* **Seguindo a arquitetura:** Todo o desenvolvimento foi feito para popular a camada `raw` (bronze), conforme o padr√£o Medallion que usamos no projeto.

### Maiores Dificuldades

* **Itera√ß√£o no Airflow:** Fazer a DAG rodar um fluxo de tarefas para cada deputado (uma itera√ß√£o din√¢mica) foi mais complexo do que eu imaginava.
* **L√≥gica de `UPSERT`:** Pensar na melhor forma de implementar o `UPSERT` de um jeito eficiente dentro do Airflow deu um certo trabalho.
* **Defini√ß√£o das chaves √∫nicas:** Acertar as chaves prim√°rias para cada tabela foi um ponto crucial e desafiador para o `UPSERT` funcionar corretamente.

### Aprendizados

* **Workflows din√¢micos no Airflow:** Aprendi na pr√°tica como criar pipelines que se adaptam aos dados de entrada, e n√£o apenas fluxos est√°ticos.
* **Import√¢ncia da idempot√™ncia:** Ficou muito claro para mim o quanto a idempot√™ncia √© essencial para ter pipelines de dados confi√°veis.
* **Consumo de APIs do governo:** Entendi melhor as boas pr√°ticas para lidar com APIs p√∫blicas, como tratar diferentes respostas e organizar os dados brutos.
* **Colabora√ß√£o em ETL:** As conversas com a equipe sobre o escopo e as chaves dos dados foram muito importantes para o desenvolvimento do processo de ETL.

### Plano para a Pr√≥xima Sprint

* [ ] **Finalizar e testar a DAG:** Concluir o c√≥digo, rodar os testes com a amostra de 50 IDs e confirmar que o reprocessamento n√£o duplica nada.
* [ ] **Refatorar o c√≥digo:** Depois de validar, quero otimizar o c√≥digo, melhorando as consultas e a organiza√ß√£o geral.
* [ ] **Criar a documenta√ß√£o:** Documentar como a DAG funciona, as decis√µes que tomei e os endpoints que ela usa.
* [ ] **Planejar a camada Silver:** Come√ßar a pensar em como vamos limpar e transformar esses dados brutos para a pr√≥xima etapa da arquitetura.

### Reflex√µes Pessoais

Senti que meu aprendizado deu um salto nesta sprint, passando da teoria para a pr√°tica. Trabalhar diretamente com os dados dos deputados me conectou mais com o prop√≥sito do GovHub-br. Percebi que n√£o estamos s√≥ juntando n√∫meros, mas montando um perfil detalhado de quem toma as decis√µes no pa√≠s.

Resolver o desafio t√©cnico do `UPSERT` e da escalabilidade foi bem gratificante. Ver o c√≥digo funcionando me deixa confiante de que estou construindo algo s√≥lido. A colabora√ß√£o com o time foi fundamental. Estou animado para fechar essa tarefa e ver os dados sendo usados para gerar mais transpar√™ncia.
